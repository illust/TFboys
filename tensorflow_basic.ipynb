{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Mechanics\n",
    "1. Build graph using tensorflow operations\n",
    "2. Feed data and run graph (operation) sess.run (op)\n",
    "3. Update variables in the graph (and return values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build graph using tensorflow operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"Const_10:0\", shape=(), dtype=float32) node2: Tensor(\"Const_11:0\", shape=(), dtype=float32)\n",
      "node3: Tensor(\"Add_5:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "node1 = tf.constant(3,tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "node3 = tf.add(node1,node2)\n",
    "\n",
    "print(\"node1:\",node1,\"node2:\",node2)\n",
    "print(\"node3:\",node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tips: What is data flow graph?\n",
    "- Nodes in the graph represent mathematical operations.\n",
    "- Edges represent the multimensional data arrays(tensors) communicated between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feed data and run graph (operation) `sess.run` (op)\n",
    "- Update variables in the graph (and return values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1,node2):  [3.0, 4.0]\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1,node2): \",sess.run([node1,node2]))\n",
    "print(\"sess.run(node3): \",sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder\n",
    "为投喂的tensor插入占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a,b)\n",
    "\n",
    "print(sess.run(adder_node,feed_dict={a: 3,b: 4.5}))\n",
    "print(sess.run(adder_node,feed_dict={a: [1,3],b: [2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything is Tensor\n",
    "如同java中一切都是对象一样，tf中一切都是tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_14:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "t = tf.constant(3) # a rank 0 tensor; this is a scalar with shpae []\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_15:0\", shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t1 = tf.constant([1.,2.,3.]) # a rank 1 tensor; this is a vector with shape [3]\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_16:0\", shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t2 = tf.constant([[1.,2.,3.],[4.,5.,6.]]) # a rank 2 tensor; a matrix with shape [2,3]\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_17:0\", shape=(2, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t3 = tf.constant([[[1.,2.,3.]],[[7.,8.,9.]]]) # a rank 3 tensor with shape [2,1,3]\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Ranks ,Shapes, and Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank | Math entity | Python example | Shape\n",
    "----- | ----- | ------ | ------\n",
    "0 | Scalar(magnitude only) | s = 483 | []\n",
    "1 | Vector(magnitude and direction) | v = [1.1,2.2,3.3] | [D0]\n",
    "2 | Matrix(table of numbers) | m = [[1,2,3],[4,5,6],[7,8,9]] | [D0,D1]\n",
    "3 | 3-Tensor(cube of numbers) | t = [[[2],[4],[6]],[[8],[10],[12]],[[14],[16],[18]]] | [D0,D1,D2]  \n",
    "n | n-Tensor(you get the idea) | ... | [D0,D1,...Dn-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type | Python type | Description\n",
    "----- | ----- | ------\n",
    "DT_FLOAT | tf.float32 | 32 bits floating point.\n",
    "DT_DOUBLE | tf.float64 | 64 bits floating point.\n",
    "DT_INT8 | tf.int8 | 8 bits signed integer.\n",
    "DT_INT16 | tf.int16 | 16 bits signed integer.\n",
    "DT_INT32 | tf.int32 | 32 bits signed integer.\n",
    "DT_INT64 | tf.int64 | 64 bits signed integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Regression\n",
    "- Logistic Regression (Binary classification)\n",
    "- Softmax Classification\n",
    "- Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Build graph using TF operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]),name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]),name='bias')\n",
    "\n",
    "# Our hypothesis WX+b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2/3. Run/update graph and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9067926 [0.66933] [-0.6928747]\n",
      "100 0.018648325 [1.1586004] [-0.36054745]\n",
      "200 0.011523545 [1.1246778] [-0.28342173]\n",
      "300 0.0071208426 [1.098008] [-0.22279543]\n",
      "400 0.0044002617 [1.0770434] [-0.17513762]\n",
      "500 0.0027191015 [1.0605634] [-0.13767432]\n",
      "600 0.0016802367 [1.0476083] [-0.10822459]\n",
      "700 0.0010382858 [1.0374244] [-0.08507457]\n",
      "800 0.0006415971 [1.029419] [-0.06687632]\n",
      "900 0.0003964696 [1.0231261] [-0.05257095]\n",
      "1000 0.00024499264 [1.0181792] [-0.04132547]\n",
      "1100 0.00015139126 [1.0142905] [-0.03248551]\n",
      "1200 9.355049e-05 [1.0112336] [-0.02553659]\n",
      "1300 5.780921e-05 [1.0088307] [-0.02007414]\n",
      "1400 3.5722347e-05 [1.0069418] [-0.01578013]\n",
      "1500 2.207385e-05 [1.0054568] [-0.01240462]\n",
      "1600 1.3641221e-05 [1.0042896] [-0.00975136]\n",
      "1700 8.429578e-06 [1.0033722] [-0.00766557]\n",
      "1800 5.2089267e-06 [1.0026507] [-0.00602592]\n",
      "1900 3.219208e-06 [1.0020839] [-0.00473705]\n",
      "2000 1.9895674e-06 [1.0016384] [-0.00372406]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(step,sess.run(cost),sess.run(W),sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Look at [here](https://stackoverflow.com/questions/32986123/why-the-cost-function-of-logistic-regression-has-a-logarithmic-expression), its FAQ talks about the question ``why the cost function of logistic regression has a logarithmic expression?``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax Function\n",
    "Look at [here](http://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks),it talks about ``Epoch vs iteration when training neural networks``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
